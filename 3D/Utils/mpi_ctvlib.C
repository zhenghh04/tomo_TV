//
//  tlib.cpp
//  TV
//
//  Created by Hovden Group on 5/6/19.
//  Copyright Â© 2019 Jonathan Schwartz. All rights reserved.
//

#include "mpi_ctvlib.h"
#include <Eigen/SparseCore>
#include <Eigen/Core>
#include <iostream>
#include <cmath>
#include <random>
#include <iostream>
#include <mpi.h>
#include "hdf5.h"

#define PI 3.14159265359

using namespace Eigen;
using namespace std;


typedef Eigen::Matrix<float, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor> Mat;
typedef Eigen::SparseMatrix<float, Eigen::RowMajor> SpMat;

void mpi_ctvlib::loadMeasurementMatrix(char *fname) {
  hid_t fd = H5Fopen(fname, H5F_ACC_RDONLY, H5P_DEFAULT);
  hid_t dset = H5Dopen(fd, "/matrix", H5P_DEFAULT);
  hid_t space_s = H5Dget_space(dset);
  hsize_t gdims[2];
  int ndims = H5Sget_simple_extent_dims(space_s, gdims, NULL);

  if (rank==0) {
    cout << "* reading measurement matrix from " << fname << endl; 
    cout << "* Dim: " << gdims[0] << "x" << gdims[1] << endl; 
  }
  float *Mat = new float[gdims[0]*gdims[1]];
  H5Dread(dset, H5T_NATIVE_FLOAT, H5S_ALL, H5S_ALL, H5P_DEFAULT, Mat);
  H5Dclose(dset);
  H5Fclose(fd);
  for (int i=0; i < gdims[1]; i++)
  {
    A.coeffRef(Mat[i], Mat[gdims[1]+i]) = Mat[gdims[1]*2+i];
  }
  A.makeCompressed();
  delete [] Mat; 
} 


void mpi_ctvlib::loadVolume(char *fname) {
  MPI_Comm_size(MPI_COMM_WORLD, &nproc); 
  MPI_Comm_rank(MPI_COMM_WORLD, &rank); 
  if (rank==0) cout << "* Reading data from " << fname << endl; 
  hid_t plist_id = H5Pcreate(H5P_FILE_ACCESS);
  MPI_Info info = MPI_INFO_NULL; 
  H5Pset_fapl_mpio(plist_id, MPI_COMM_WORLD, info); 
  hid_t fd = H5Fopen(fname, H5F_ACC_RDONLY, plist_id);
  hid_t dset = H5Dopen(fd, "/tiltSeries", H5P_DEFAULT);

  hid_t space_s = H5Dget_space(dset);
  hsize_t gdims[3];
  int ndims = H5Sget_simple_extent_dims(space_s, gdims, NULL);
  unsigned int Nslice = gdims[0]; 
  unsigned int Nray = gdims[1]; 
  unsigned int Nproj = gdims[2];
  // get the local dimsion for parallel read
  unsigned int Nslice_loc = int(Nslice/nproc);
  unsigned int first_slice = rank*Nslice_loc;
  if (rank < Nslice%nproc){
    Nslice_loc++;
    first_slice += rank%nproc; }
  int last_slice = first_slice + Nslice_loc - 1; 

  hsize_t ldims[3] = {Nslice_loc, Nray, Nproj};
  hid_t fspace = H5Screate_simple(3, gdims, NULL);
  hid_t mspace = H5Screate_simple(3, ldims, NULL);
  hsize_t offset[3] = {first_slice, 0, 0}; 
  hsize_t count [3] = {1, 1, 1};
  H5Sselect_hyperslab(fspace, H5S_SELECT_SET, offset, NULL, ldims, count); 
  hid_t dxf_id = H5Pcreate(H5P_DATASET_XFER);
  H5Pset_dxpl_mpio(dxf_id, H5FD_MPIO_COLLECTIVE);
  float *tiltSeries = new float[Nslice_loc*Nray*Nproj]; 
  if (rank==0) {
    cout << "* Nslice: " << Nslice << endl;  
    cout << "* Nray: " << Nray << endl;  
    cout << "* Nproj: " << Nproj << endl;  
  }
  H5Dread(dset, H5T_NATIVE_FLOAT, mspace, fspace, dxf_id, tiltSeries); 
  H5Pclose(plist_id);
  H5Sclose(fspace);
  H5Sclose(mspace);
  H5Dclose(dset);
  H5Pclose(dxf_id);
  H5Fclose(fd);
  init(Nslice, Nray, Nproj);

  for(int i=0; i<Nslice_loc; i++) {
    memcpy(&original_volume[i](0, 0), &tiltSeries[i*Nray*Nproj], Nray*Nproj*sizeof(float));
  }
} 

void mpi_ctvlib::init(int Ns, int Nray, int Nproj)
{
    //Intialize all the Member variables.
    Nslice = Ns;
    Ny = Nray;
    Nz = Nproj;
    Nrow = Nray*Nproj;
    Ncol = Ny*Nz;
    A.resize(Nrow,Ncol);
    innerProduct.resize(Nrow);

    MPI_Comm_size(MPI_COMM_WORLD, &nproc);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    
    //Calculate the number of slices for each rank.
    Nslice_loc = int(Nslice/nproc);
    first_slice = rank*Nslice_loc;
    if (rank < Nslice%nproc){
        Nslice_loc++;
        first_slice += rank%nproc; }
    last_slice = first_slice + Nslice_loc - 1; 

    b.resize(Nslice_loc, Nrow);
    g.resize(Nslice_loc, Nrow);

    //All the rank Initialize all the 3D-matrices.
        
   //Final Reconstruction.
    recon = new Mat[Nslice_loc+2]; 
    /* I added two more slices, Mat[Nslice_loc] on rank N = Mat[0] on rank N+1
     */
    // Temporary copy for measuring changes in TV and ART.
    temp_recon = new Mat[Nslice_loc+2];
        
    // Temporary copy for measuring 3D TV - Derivative.
    tv_recon = new Mat[Nslice_loc+2];
        
        // Original Volume for Simulation Studies.
    original_volume = new Mat[Nslice_loc+2];

        // Initialize the 3D Matrices as zeros.
    #pragma omp parallel for
    for (int i=0; i < Nslice_loc+2; i++)
    {
         recon[i] = Mat::Zero(Ny, Nz);
         temp_recon[i] = Mat::Zero(Ny, Nz);
         tv_recon[i] = Mat::Zero(Ny,Nz);
	 original_volume[i] = Mat::Zero(Ny, Nz);
    }
}

int mpi_ctvlib::get_Nslice_loc()
{
    return Nslice_loc;
}

int mpi_ctvlib::get_first_slice()
{
    return first_slice;
}

int mpi_ctvlib::get_rank() {
  return rank;
}

int mpi_ctvlib::get_nproc() {
  return nproc; 
}
//Import tilt series (projections) from Python.
void mpi_ctvlib::setTiltSeries(Mat in)
{
    b = in;
}

// Import the original volume from python.
void mpi_ctvlib::setOriginalVolume(Mat in, int slice)
{
    original_volume[slice] = in;
}

// Create projections from Volume (for simulation studies)
void mpi_ctvlib::create_projections()
{
    for (int s = 0; s < Nslice_loc; s++)
    {
        Mat& mat_slice = original_volume[s];
        mat_slice.resize(mat_slice.size(),1);
        VectorXf vec_recon = mat_slice;
        #pragma omp parallel for
        for (int i=0; i < Nrow; i++)
        {
            b(s,i) = A.row(i).dot(vec_recon);
        }
        mat_slice.resize(Ny,Nz);
    }
}

// Add poisson noise to projections.
void mpi_ctvlib::poissonNoise(int Nc)
{
    Mat temp_b = b;
    float N = b.sum();
    float mean;
    if (nproc ==1 ) {
      mean = N/b.size(); 
    } else {
      MPI_Allreduce(&N, &mean, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD);
      mean = mean/Nslice/Nrow;
    }
    b = b/mean*Nc; 
    std::default_random_engine generator;
    for(int i=0; i < b.size(); i++)
    {
       std::poisson_distribution<int> distribution(b(i));
       b(i) = distribution(generator);
    }
    float scale = 1;

    b = b / Nc * mean;

    //    temp_b.array() -= b.array();
    // float std = sqrt( ( temp_b.array() - temp_b.mean() ).square().sum() / (temp_b.size() - 1));
}


// ART Reconstruction.
void mpi_ctvlib::ART(float beta, int dyn_ind)
{
//    
    //No dynamic reconstruction, assume fully sampled batch.
    if (dyn_ind == -1) { dyn_ind = Nrow; }
    //Calculate how many projections were sampled.
    else { dyn_ind *= Ny; }
    
    #pragma omp parallel for
    for (int s=0; s < Nslice_loc; s++)
    {
        Mat& mat_slice = recon[s];
        mat_slice.resize(mat_slice.size(),1);
        VectorXf vec_recon = mat_slice;
        float a;
        for(int j=0; j < dyn_ind; j++)
        {
            a = ( b(s,j) - A.row(j).dot(vec_recon) ) / innerProduct(j);
            vec_recon += A.row(j).transpose() * a * beta;
        }
        mat_slice = vec_recon;
        mat_slice.resize(Ny, Nz);
    }
}


void mpi_ctvlib::updateLeftSlice(Mat *vol) {
    /*
    Need to make sure this is OK. 
    */
    MPI_Status status;
    int tag = 0;
    if (nproc>1) {
#ifdef DEBUG
      cout << "rank" << rank << "sending the message" << endl; 
#endif
      MPI_Send(&vol[Nslice_loc-1](0, 0), Ny*Nz, MPI_FLOAT, (rank+1)%nproc, tag, MPI_COMM_WORLD);
#ifdef DEBUG
      cout << "rank" << rank << "sending the message - done" << endl; 
#endif
      MPI_Recv(&vol[Nslice_loc+1](0, 0), Ny*Nz, MPI_FLOAT, (rank-1+nproc)%nproc, tag, MPI_COMM_WORLD, &status);
#ifdef DEBUG
      cout << "message received" << endl; 
#endif
    } else {
      vol[Nslice_loc+1] = vol[Nslice_loc-1];
    }

}


void mpi_ctvlib::updateRightSlice(Mat *vol) {
    MPI_Status status;
    int tag = 0;
    if (nproc>1) {
#ifdef DEBUG
      cout << "rank" << rank << "sending the message" << endl; 
#endif
      MPI_Send(&vol[0](0, 0), Ny*Nz, MPI_FLOAT, (rank-1+nproc)%nproc, tag, MPI_COMM_WORLD);
#ifdef DEBUG
      cout << "rank" << rank << "sending the message - done" << endl; 
#endif
      MPI_Recv(&vol[Nslice_loc](0, 0), Ny*Nz, MPI_FLOAT, (rank+1)%nproc, tag, MPI_COMM_WORLD, &status);
#ifdef DEBUG
      cout << "message received" << endl; 
#endif
    } else {
      vol[Nslice_loc] = vol[0];
    }
}

// Stochastic ART Reconstruction.
void mpi_ctvlib::sART(float beta, int dyn_ind)
{
    //No dynamic reconstruction, assume fully sampled batch.
    if (dyn_ind == -1) { dyn_ind = Nrow; }
    //Calculate how many projections were sampled.
    else { dyn_ind *= Ny; }
    
    // Create a random permutation of indices from [0,dyn_ind].
    std::vector<int> r_ind = rand_perm(dyn_ind);
    
    #pragma omp parallel for
    for (int s=0; s < Nslice_loc; s++)
    {
        Mat& mat_slice = recon[s];
        mat_slice.resize(mat_slice.size(),1);
        VectorXf vec_recon = mat_slice;
        float a;
        for(int j=0; j < dyn_ind; j++)
        {
            j = r_ind[j];
            a = ( b(s,j) - A.row(j).dot(vec_recon) ) / innerProduct(j);
            vec_recon += A.row(j).transpose() * a * beta;
        }
        mat_slice = vec_recon;
        mat_slice.resize(Ny, Nz);
    }
}

std::vector<int> mpi_ctvlib::rand_perm(int n)
{
    std::vector<int> a(n);
    for (int i=0; i < n; i++)
    {
        a[i] = i;
    }
    std::random_device rd;
    std::mt19937 g(rd());
    std::shuffle(a.begin(), a.end(), g);
    return a;
}

// SIRT Reconstruction.
void mpi_ctvlib::SIRT(float beta, int dyn_ind)
{
    //No dynamic reconstruction, assume fully sampled batch.
    if (dyn_ind == -1) { dyn_ind = Nrow; }
    //Calculate how many projections were sampled.
    else { dyn_ind *= Ny; }
    
    #pragma omp parallel for
    for (int s=0; s < Nslice_loc; s++)
    {
        Mat& mat_slice = recon[s];
        mat_slice.resize(mat_slice.size(),1);
        VectorXf vec_recon = mat_slice;
        vec_recon += A.transpose() * ( b.row(s).transpose() - A * vec_recon ) * beta;
        mat_slice = vec_recon;
        mat_slice.resize(Ny, Nz);
    }
}

//Calculate Lipshits Gradient (for SIRT). 
void mpi_ctvlib::lipschits()
{
    VectorXf f(Ncol);
    f.setOnes();
    float L = (A.transpose() * (A * f)).maxCoeff();
}

// Remove Negative Voxels.
void mpi_ctvlib::positivity()
{
    #pragma omp parallel for
    for(int i=0; i<Nslice_loc; i++)
    {
      recon[i] = (recon[i].array() < 0).select(0, recon[i]);
    }
}

// Set Background Value
void mpi_ctvlib::set_background(float b) 
{
    #pragma omp parallel for
    for(int i=0; i<Nslice_loc; i++)
    {
      recon[i] = (recon[i].array() == 0).select(b, recon[i]);
    }
}

// Row Inner Product of Measurement Matrix.
void mpi_ctvlib::normalization()
{
    #pragma omp parallel for
    for (int i = 0; i < Nrow; i++)
    {
        innerProduct(i) = A.row(i).dot(A.row(i));
    }
}

// Create Local Copy of Reconstruction. 
void mpi_ctvlib::copy_recon()
{
  #pragma omp parallel for 
  for (int i=0; i<Nslice_loc; i++)
    memcpy(&temp_recon[i](0,0), &recon[i](0, 0), Ny*Nz*sizeof(float));
  //memcpy(temp_recon, recon, sizeof(recon));
}

// Measure the 2 norm between temporary and current reconstruction.
float mpi_ctvlib::matrix_2norm()
{
    float L2, L2_loc;
    L2_loc = 0.0; 
    #pragma omp parallel for reduction(+:L2_loc)
    for (int s =0; s < Nslice_loc; s++)
    {
        L2_loc += ( recon[s].array() - temp_recon[s].array() ).square().sum();
    }
    if (nproc==1) 
      return sqrt(L2_loc);
    else {
      MPI_Allreduce(&L2_loc, &L2, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD);
      return sqrt(L2);
    }
}

// Measure the 2 norm between experimental and reconstructed projections.
float mpi_ctvlib::vector_2norm()
{
  float v2_loc = (g - b).norm();
  float v2; 
  if (nproc==1) 
    v2 = v2_loc/g.size(); 
  else {
    v2_loc = v2_loc*v2_loc; 
    MPI_Allreduce(&v2_loc, &v2, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD);
    v2 = sqrt(v2)/Nslice/Nrow; 
  }
  return v2; 
}

// Measure the 2 norm for projections when data is 'dynamically' collected.
float mpi_ctvlib::dyn_vector_2norm(int dyn_ind)
{
  /* TODO
     we have to figure out the reduced version for this.
   */
    dyn_ind *= Ny;
    return ( g.leftCols(dyn_ind) - b.leftCols(dyn_ind) ).norm() / g.leftCols(dyn_ind).size();
}

// Foward project the data.
void mpi_ctvlib::forwardProjection(int dyn_ind)
{
    //No dynamic reconstruction, assume fully sampled batch.
    if (dyn_ind == -1) { dyn_ind = Nrow; }
    //Calculate how many projections were sampled.
    else { dyn_ind *= Ny; }
    
    #pragma omp parallel for
    for (int s = 0; s < Nslice_loc; s++)
    {
        Mat& mat_slice = recon[s];
        mat_slice.resize(mat_slice.size(),1);
        VectorXf vec_recon = mat_slice;
        for (int i=0; i < dyn_ind; i++)
        {
            g(s,i) = A.row(i).dot(vec_recon);
        }
        mat_slice.resize(Ny,Nz);
    }
    
    //TODO: Collect the data to merge into one reprojection vector (g).
}

// Measure the RMSE (simulation studies)
float mpi_ctvlib::rmse()
{
    float rmse, rmse_loc;
    rmse_loc = 0.0; 
    #pragma omp parallel for reduction(+:rmse_loc)
    for (int s = 0; s < Nslice_loc; s++)
    {
        rmse_loc += ( recon[s].array() - original_volume[s].array() ).square().sum();
    }

    //MPI_Reduce.
    if (nproc==1) 
      rmse = rmse_loc;
    else 
      MPI_Allreduce(&rmse_loc, &rmse, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD);
    rmse = sqrt( rmse / (Nslice * Ny * Nz ) );
    return rmse;
}

// Load Measurement Matrix from Python.
void mpi_ctvlib::loadA(Eigen::Ref<Mat> pyA)
{
    for (int i=0; i <pyA.cols(); i++)
    {
        A.coeffRef(pyA(0,i), pyA(1,i)) = pyA(2,i);
    }
    A.makeCompressed();
}

//Measure Reconstruction's TV.
float mpi_ctvlib::tv_3D()
{
    float tv, tv_loc;
    float eps = 1e-6;
    int nx = Nslice_loc;
    int ny = Ny;
    int nz = Nz;
    updateRightSlice(recon);
    tv_loc = 0.0; 
    for (int i = 0; i < Nslice_loc; i++)
    {
        int ip = i+1;
        #pragma omp parallel for
        for (int j = 0; j < ny; j++)
        {
            int jp = (j+1)%ny;
            for (int k = 0; k < nz; k++)
            {
                int kp = (k+1)%ny;
                tv_recon[i](j,k) = sqrt(eps + ( recon[i](j,k) - recon[ip](j,k) ) * ( recon[i](j,k) - recon[ip](j,k) )
                                        + ( recon[i](j,k) - recon[i](jp,k) ) * ( recon[i](j,k) - recon[i](jp,k) )
                                        + ( recon[i](j,k) - recon[i](j,kp) ) * ( recon[i](j,k) - recon[i](j,kp) ));
            }
        }
        tv_loc+=tv_recon[i].sum();
    }
    //MPI_Reduce.
    if (nproc==1) 
      tv=tv_loc;
    else
      MPI_Allreduce(&tv_loc, &tv, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD);
    return tv;
}

//Measure Original Volume's TV.
float mpi_ctvlib::original_tv_3D()
{
    float tv, tv_loc;
    float eps = 1e-6;
    int nx = Nslice_loc;
    int ny = Ny;
    int nz = Nz;
    updateRightSlice(original_volume);
    tv_loc = 0.0; 
    for (int i = 0; i < Nslice_loc; i++)
    {
        int ip = i+1;
        #pragma omp parallel for
        for (int j = 0; j < ny; j++)
        {
            int jp = (j+1)%ny;
            for (int k = 0; k < nz; k++)
            {
                int kp = (k+1)%ny;
                tv_recon[i](j,k) = sqrt(eps + pow( original_volume[i](j,k) - original_volume[ip](j,k) , 2)
                                        + pow( original_volume[i](j,k) - original_volume[i](jp,k) , 2)
                                        + pow( original_volume[i](j,k) - original_volume[i](j,kp) , 2));
            }
        }
        tv_loc+= tv_recon[i].sum();
    }
    //MPI_Reduce.
    if (nproc==1) 
      tv = tv_loc;
    else
      MPI_Allreduce(&tv_loc, &tv, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD);
    return tv;
}

// TV Minimization (Gradient Descent)
void mpi_ctvlib::tv_gd_3D(int ng, float dPOCS)
{
    float eps = 1e-6;
    float tv_norm, tv_norm_loc;
    int nx = Nslice_loc;
    int ny = Ny;
    int nz = Nz;
    updateRightSlice(recon);
    updateLeftSlice(recon);
    //Calculate TV Derivative Tensor.
    
    for(int g=0; g < ng; g++) {
      tv_norm_loc = 0.0; 
#pragma omp parallel for reduction(+:tv_norm_loc)
      for (int i = 0; i < nx; i++)
        {
            int ip = i+1;
            int im = (i-1+nx+2) % (nx+2);
            for (int j = 0; j < ny; j++)
            {
                int jp = (j+1) % ny;
                int jm = (j-1+ny) % ny;
                
                for (int k = 0; k < nz; k++)
                {
                    int kp = (k+1)%nz;
                    int km = (k-1+ny)%nz;
                    
                    float v1n = 3.0*recon[i](j, k) - recon[ip](j, k) - recon[i](jp, k) - recon[i](j, kp);
                    float v1d = sqrt(eps + ( recon[i](j, k) - recon[ip](j, k) ) * ( recon[i](j, k) - recon[ip](j, k) )
                                      +  ( recon[i](j, k) - recon[i](jp, k) ) * ( recon[i](j, k) - recon[i](jp, k) )
                                      +  ( recon[i](j, k) - recon[i](j, kp) ) * ( recon[i](j, k) - recon[i](j, kp) ));
                    float v2n = recon[i](j, k) - recon[im](j, k);
                    float v2d = sqrt(eps + ( recon[im](j, k) - recon[i](j, k) ) * ( recon[im](j, k) - recon[i](j, k) )
                                      +  ( recon[im](j, k) - recon[im](jp, k) ) * ( recon[im](j, k) - recon[im](jp, k) )
                                      +  ( recon[im](j, k) - recon[im](j, kp)) * ( recon[im](j, k) - recon[im](j, kp)));
                    float v3n = recon[i](j, k) - recon[i](jm, k);
                    float v3d = sqrt(eps + ( recon[i](jm, k) - recon[ip](jm, k) ) * ( recon[i](jm, k) - recon[ip](jm, k) )
                                      +  ( recon[i](jm, k) - recon[i](j, k) ) * ( recon[i](jm, k) - recon[i](j, k) )
                                      +  ( recon[i](jm, k) - recon[i](jm, kp) ) * ( recon[i](jm, k) - recon[i](jm, kp) ) );
                    float v4n = recon[i](j, k) - recon[i](j, km);
                    float v4d = sqrt(eps + ( recon[i](j, km) - recon[ip](j, km)) * ( recon[i](j, km) - recon[ip](j, km))
                                      + ( recon[i](j, km) - recon[i](jp, km)) * ( recon[i](j, km) - recon[i](jp, km))
                                      + ( recon[i](j, km) - recon[i](j, k) ) * ( recon[i](j, km) - recon[i](j, k) ) );
                    tv_recon[i](j,k) = v1n/v1d + v2n/v2d + v3n/v3d + v4n/v4d;
                    tv_norm_loc += tv_recon[i](j,k) * tv_recon[i](j,k);
                }
            }
        }
      if (nproc==1) 
	tv_norm = tv_norm_loc;
      else
        MPI_Allreduce(&tv_norm_loc, &tv_norm, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD);
      tv_norm = sqrt(tv_norm);
      
      // Gradient Descent.
#pragma omp parallel for
      for (int l = 0; l < nx; l++)
        {
	  recon[l] -= dPOCS * tv_recon[l] / tv_norm;
        }
    }
    positivity();
}

// Return Reconstruction to Python.
Mat mpi_ctvlib::getRecon(int s)
{
    /*
        TODO: now the recon is distributed to different processors. We should have a gather operator. 
    */
    return recon_gathered[s];
}

void mpi_ctvlib::save_recon(char *filename, int type=0) {
  if (type==0) {
    hid_t plist_id = H5Pcreate(H5P_FILE_ACCESS);
    MPI_Info info = MPI_INFO_NULL; 
    H5Pset_fapl_mpio(plist_id, MPI_COMM_WORLD, info); 
    hid_t fd = H5Fcreate(filename, H5F_ACC_TRUNC, H5P_DEFAULT, plist_id);
    hid_t dxf_id = H5Pcreate(H5P_DATASET_XFER);
    H5Pset_dxpl_mpio(dxf_id, H5FD_MPIO_COLLECTIVE);
    hsize_t gdims[3] = {Nslice, Ny, Nz}; 
    hsize_t ldims[3] = {Nslice_loc, Ny, Nz}; 
    hsize_t offset[3] = {first_slice, 0, 0};
    hsize_t count[3] = {1, 1, 1};
    hid_t fspace = H5Screate_simple(3, gdims, NULL); 
    hid_t mspace = H5Screate_simple(3, ldims, NULL); 
    hid_t dset = H5Dcreate(fd, "recon", H5T_NATIVE_FLOAT, fspace, H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT); 
    H5Sselect_hyperslab(fspace, H5S_SELECT_SET, offset, NULL, ldims, count); 
    float *buf = new float [Nslice_loc*Ny*Nz];
#pragma omp parallel for
    for (int i=0; i<Nslice_loc; i++)
      memcpy(&buf[i*Ny*Nz], &recon[i](0, 0), Ny*Nz*sizeof(float));

    H5Dwrite(dset, H5T_NATIVE_FLOAT, mspace, fspace, dxf_id, buf); 
    delete [] buf; 
    H5Pclose(plist_id); 
    H5Pclose(dxf_id);
    H5Sclose(fspace); 
    H5Sclose(mspace); 
    H5Dclose(dset);
    H5Fclose(fd);

  } else {
    MPI_File fh; 
    int rc= MPI_File_open(MPI_COMM_WORLD, filename, MPI_MODE_WRONLY | MPI_MODE_CREATE, MPI_INFO_NULL, &fh); 
    float *buf = new float [Nslice_loc*Ny*Nz];
#pragma omp parallel for
    for (int i=0; i<Nslice_loc; i++)
      memcpy(&buf[i*Ny*Nz], &recon[i](0, 0), Ny*Nz*sizeof(float));
    
    MPI_File_write_at(fh, sizeof(float)*first_slice*Ny*Nz, buf, Nslice_loc*Ny*Nz, MPI_FLOAT, MPI_STATUS_IGNORE);
    MPI_File_close(&fh);
    MPI_File_sync(fh);
    if (rank==0) cout << "write done " << endl; 
    delete [] buf; 
  }
}

Mat mpi_ctvlib::get_projections()
{
    return b;
}

void mpi_ctvlib::restart_recon()
{
    #pragma omp parallel for
    for (int s = 0; s < Nslice_loc; s++)
    {
        recon[s] = Mat::Zero(Ny,Ny);
    }
}
